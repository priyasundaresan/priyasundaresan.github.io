<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Priya Sundaresan</title>
  
  <meta name="author" content="Priya Sundaresan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Priya Sundaresan</name>
              </p>
              <p>I am a <strong>final year PhD candidate at Stanford University</strong>, co-advised by Professors <a href="https://dorsa.fyi/">Dorsa Sadigh</a>  and <a href="https://web.stanford.edu/~bohg/">Jeannette Bohg</a>. I am interested in imitation learning and representation learning for real-world manipulation. I am funded by the <a href="https://www.nsfgrfp.org/">National Science Foundation Graduate Fellowship</a>.
              </p>
              <p>Before Stanford, I completed my B.S. and M.S. at UC Berkeley, where I worked with Professor <a href='goldberg.berkeley.edu'>Ken Goldberg</a> in the <a href='autolab.berkeley.edu'>AUTOLAB</a>. I have also previously spent summers interning at Amazon Robotics, [Google] Intrinsic, and Google DeepMind.</p>
              <p>Please feel free to reach out!</p>
              <p style="text-align:center">
                <a href="mailto:priyasun@stanford.edu">priyasun@stanford.edu</a> &nbsp/&nbsp
                <a href="data/PriyaSundaresanCV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/priyasundaresan/">Github</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=7SUquR4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/priyasun_?lang=en">X</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/PriyaSundaresan.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/PriyaSundaresan.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <br><br>Papers are ordered by recency, and representative works are highlighted.
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

         <tr class="highlight">
            <td style="padding:20px;width:25%;vertical-align:middle;text-align:center">
             <img src="images/homer.gif" alt="homer" width="280">
            </td>
            <td width="75%" valign="middle">
              <a href="https://sphinx-manip.github.io/">
                <papertitle>HoMeR: Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan</strong>, Rhea Malhotra, Phillip Miao, Jingyun Yang, Jimmy Wu, Hengyuan Hu, Rika Antonova, Francis Engelmann, Dorsa Sadigh, Jeannette Bohg 
              
              <br>
              <span class="conference-badge badge-preprint">Pre-Print 2025</span>
              <br>
              <a href="https://homer-manip.github.io/">Website</a> / <a href="https://arxiv.org/abs/2506.01185">PDF</a> 
            </td>
         </tr>

         <tr class="highlight">
            <td style="padding:20px;width:25%;vertical-align:middle;text-align:center">
             <img src="images/sphinx.gif" alt="sphinx" width="280">
            </td>
            <td width="75%" valign="middle">
              <a href="https://sphinx-manip.github.io/">
                <papertitle>What's the Move? Hybrid Imitation Learning via Salient Points</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan*</strong>, Hengyuan Hu*, Quan Vuong, Jeannette Bohg, Dorsa Sadigh
              
              <br>
              <span class="conference-badge badge-iclr">ICLR 2025</span>
              <br>
              <a href="https://sphinx-manip.github.io/">Website</a> / <a href="https://arxiv.org/abs/2412.05426">PDF</a> 
            </td>
         </tr>

         <tr class="highlight">
            <td style="padding:20px;width:25%;vertical-align:middle;text-align:center">
              <img src="images/mtpi.gif" alt="mtpi" width="280">
            </td>
            <td width="75%" valign="middle">
              <a href="https://portal-cornell.github.io/motion_track_policy/">
                <papertitle>Motion Tracks: A Unified Representation for Human-Robot Transfer in Few-Shot Imitation Learning</papertitle>
              </a>
              <br>
              Juntao Ren, <strong>Priya Sundaresan</strong>, Dorsa Sadigh, Sanjiban Choudhury, Jeannette Bohg
              
              <br>
              <span class="conference-badge badge-icra">ICRA 2025</span>
              <br>
              <a href="https://portal-cornell.github.io/motion_track_policy/">Website</a> / <a href="https://portal-cornell.github.io/motion_track_policy/">PDF</a> 
            </td>
         </tr>

         <tr class="highlight">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/flair.gif" alt="flair" width="280" height="150">
            </td>
            <td width="75%" valign="middle">
              <a href="https://flair-robot.github.io/assets/flair.pdf">
                <papertitle>FLAIR: Feeding via Long-horizon AcquIsition of Realistic dishes</papertitle>
              </a>
              <br>
              Rajat Kumar Jenamani*, <strong>Priya Sundaresan*</strong>, Maram Sakr, Tapomayukh Bhattacharjee‚Ä†, Dorsa Sadigh‚Ä†
              
              <br>
              <span class="conference-badge badge-rss">RSS 2024</span>
              <br>
              <a href="https://flair-robot.github.io/">Website</a> / <a href="https://flair-robot.github.io/assets/flair.pdf">PDF</a>  / <a href="https://www.sfchronicle.com/tech/article/stanford-robotics-lab-home-helpers-19869354.php">SF Chronicle</a>
            </td>
         </tr>

         <tr class="highlight">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rtsketch.gif" alt="rtsketch" width="280" height="150">
            </td>
            <td width="75%" valign="middle">
              <a href="https://rt-sketch.github.io">
                <papertitle>RT-Sketch: Goal-Conditioned Imitation Learning from Hand-Drawn Sketches</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan</strong>, Quan Vuong, Jiayuan Gu, Peng Xu, Ted Xiao, Sean Kirmani, Tianhe Yu, Michael Stark, Ajinkya Jain, Karol Hausman, Dorsa Sadigh*, Jeannette Bohg*, Stefan Schaal* 
              <br>
              <span class="conference-badge badge-corl">CoRL 2024</span>
              <br><font color="#b80647"><strong>‚òÖOral Presentation‚òÖ</strong></font>
              <br>
              <a href="https://rt-sketch.github.io">Website</a> / <a href="https://rt-sketch.github.io/assets/rt_sketch.pdf">PDF</a> / <a href="https://venturebeat.com/automation/deepmind-and-stanfords-new-robot-control-model-follow-instructions-from-sketches/">VentureBeat</a> 
            </td>
         </tr>

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rttraj.gif" alt="rttraj" width="280" height="240">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2311.01977">
                <papertitle>RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches</papertitle>
              </a>
              <br>
              Jiayuan Gu, Sean Kirmani, Paul Wohlhart, Yao Lu, Montserrat Gonzalez Arenas, Kanishka Rao, Wenhao Yu, Chuyuan Fu, Keerthana Gopalakrishnan, Zhuo Xu, <strong>Priya Sundaresan</strong>, Peng Xu, Hao Su, Karol Hausman, Chelsea Finn, Quan Vuong, Ted Xiao
              <br>
              <span class="conference-badge badge-iclr">ICLR 2024</span>
              <br>
              <a href="https://rt-trajectory.github.io/">Website</a> / <a href="https://rt-trajectory.github.io/pdf/RT_Trajectory.pdf">PDF</a> 
            </td>
         </tr>

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rtx.gif" alt="rttraj" width="280" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://robotics-transformer-x.github.io/">
                <papertitle>Open X-Embodiment: Robotic Learning Datasets and RT-X Models</papertitle>
              </a>
              <br>
              Open X-Embodiment Collaboration [>150 authors]
              <br>
              <span class="conference-badge badge-icra">ICRA 2024</span>
              <br>
              <a href="https://robotics-transformer-x.github.io/">Website</a> / <a href="https://arxiv.org/abs/2310.08864">PDF</a> 
            </td>
         </tr>


         <tr class="highlight">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/kite.gif" alt="kite" width="280" height="150">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2306.16605">
                <papertitle>KITE: Keypoint-Conditioned Policies for Semantic Manipulation</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan</strong>, Suneel Belkhale, Dorsa Sadigh, Jeannette Bohg
              <br>
              <span class="conference-badge badge-corl">CoRL 2023</span>
              <br>
              <a href="http://tinyurl.com/kite-site">Website</a> / <a href="https://arxiv.org/pdf/2306.16605.pdf">PDF</a> 
            </td>
          </tr>

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/spaghetti.gif" alt="spaghetti" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2309.05197">
                <papertitle>Learning Sequential Acquisition Policies for Robot-Assisted Feeding</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan</strong>, Jiajun Wu, Dorsa Sadigh
              <br>
              <span class="conference-badge badge-corl">CoRL 2023</span>
              <br>
              <a href="https://sites.google.com/view/vaporsbot">Website</a> / <a href="https://arxiv.org/pdf/2309.05197.pdf">PDF</a> 
            </td>
          </tr>

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bite_transfer.gif" alt="bite transfer" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2211.12705">
                <papertitle>In-Mouth Robotic Bite Transfer with Visual and Haptic Sensing</papertitle>
              </a>
              <br>
              Lorenzo Shaikewitz*, Yilin Wu*, Suneel Belkhale*, Jennifer Grannen, <strong>Priya Sundaresan</strong>, Dorsa Sadigh
              <br>
              <span class="conference-badge badge-icra">ICRA 2023</span>
              <br>
              <a href="https://sites.google.com/view/bitetransfericra2023/home">Website</a> / <a href="https://arxiv.org/pdf/2211.12705.pdf">PDF</a> 
            </td>
          </tr>


         <tr class="highlight">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/skewering.gif" alt="skewering" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2211.14648">
                <papertitle>Learning Visuo-Haptic Skewering Strategies for Robot-Assisted Feeding</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan</strong>, Suneel Belkhale, Dorsa Sadigh
              <br>
              <span class="conference-badge badge-corl">CoRL 2022</span>
              <br>
              <a href="http://tinyurl.com/robotskewering">Website</a> / <a href="https://arxiv.org/pdf/2211.14648.pdf">PDF</a> / <a href="https://hai.stanford.edu/news/building-precise-assistive-feeding-robot-can-handle-any-meal">Stanford HAI Blogpost</a>
            </td>
          </tr>


         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/diffcloud.gif" alt="diffcloud" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2204.03139">
                <papertitle>DiffCloud: Real-to-Sim from Point Clouds with Differentiable Simulation and Rendering of Deformable Objects</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan</strong>, Rika Antonova, Jeannette Bohg
              <br>
              <span class="conference-badge badge-iros">IROS 2022</span>
              <br>
              <a href="https://diffcloud.github.io/">Website</a> / <a href="https://arxiv.org/abs/2204.03139">PDF</a> 
            </td>
          </tr>


         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ral2022.gif" alt="bayes-real2sim" width="280" height="140">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.05068">
                <papertitle>A Bayesian Treatment of Real-to-Sim for Deformable Object Manipulation</papertitle>
              </a>
              <br>
              Rika Antonova, Jingyun Yang, <strong>Priya Sundaresan</strong>, Dieter Fox, Fabio Ramos, Jeannette Bohg
              <br>
              <span class="conference-badge badge-ral">RA-L 2022</span>
              <br>
              <a href="https://arxiv.org/abs/2112.05068">PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iros2021.gif" alt="mult-cable-untangling" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2106.02252">
                <papertitle>Disentangling Dense Multi-Cable Knots</papertitle>
              </a>
              <br>
               Vainavi Viswanath*, Jennifer Grannen*, <strong>Priya Sundaresan*</strong>, Brijen Thananjeyan, Ashwin Balakrishna, Ellen Novoseller, Jeffrey Ichnowski, Michael Laskey, Joseph E. Gonzalez, Ken Goldberg
              <br>
              <span class="conference-badge badge-iros">IROS 2021</span>
              <br>
              <a href="https://sites.google.com/view/multi-cable-disentangling">Website</a> / <a href="https://arxiv.org/pdf/2106.02252.pdf">PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rss2021.gif" alt="nonplanar-untangling" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://roboticsconference.org/program/papers/013/">
                <papertitle>Untangling Dense Non-Planar Knots by Learning Manipulation Features and Recovery Policies</papertitle>
              </a>
              <br>
               <strong>Priya Sundaresan*</strong>, Jennifer Grannen*, Brijen Thananjeyan, Ashwin Balakrishna, Jeffrey Ichnowski, Ellen Novoseller, Minho Hwang, Michael Laskey, Joseph E. Gonzalez, Ken Goldberg
              <br>
              <span class="conference-badge badge-rss">RSS 2021</span>
              <br>
              <a href="https://tinyurl.com/rssuntangling">Website</a> / <a href="http://www.roboticsproceedings.org/rss17/p013.pdf">PDF</a>
            </td>
          </tr>


         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icra2021.gif" alt="descriptors-fabric" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2003.12698">
                <papertitle>Learning Dense Visual Correspondences in Simulation to Smooth and Fold Real Fabrics</papertitle>
              </a>
              <br>
              Aditya Ganapathi, <strong>Priya Sundaresan</strong>, Brijen Thananjeyan, Ashwin Balakrishna, Daniel Seita, Jennifer Grannen, Minho Hwang, Ryan Hoque, Joseph E. Gonzalez, Nawid Jamali, Katsu Yamane, Soshi Iba, Ken Goldberg
              <br>
              <span class="conference-badge badge-icra">ICRA 2021</span>
              <br>
              <a href="https://sites.google.com/view/fabric-descriptors">Website</a> / <a href="https://arxiv.org/pdf/2003.12698.pdf">PDF</a>
            </td>
          </tr>

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iros2020-wkshop.gif" alt="mmgsd" width="280" height="150">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2010.04339">
                <papertitle>MMGSD: Multi-Modal Gaussian Shape Descriptors for Correspondence Matching in 1D and 2D Deformable Objects.</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan*</strong>, Aditya Ganapathi*, Brijen Thananjeyan, Ashwin Balakrishna, Daniel Seita, Ryan Hoque, Joseph Gonzalez, Ken Goldberg
              <br>
              <span class="conference-badge badge-iros">IROS 2020</span>
   	      <br><em>Workshop on Robotic Manipulation of Deformable Objects, 2020.</em>
              <br>
              <a href="https://arxiv.org/abs/2010.04339">PDF</a>
            </td>
          </tr>


         <tr class="highlight">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/corl2020_gif.gif" alt="untangling" width="280" height="l80">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2011.04999">
                <papertitle>Untangling Dense Knots by Learning Task-Relevant Keypoints</papertitle>
              </a>
              <br>
              Jennifer Grannen*, <strong>Priya Sundaresan*</strong>, Brijen Thananjeyan, Jeffrey Ichnowski, Ashwin Balakrishna, Minho Hwang, Vainavi Viswanath, Michael Laskey, Joseph E. Gonzalez, Ken Goldberg
              <br>
              <span class="conference-badge badge-corl">CoRL 2020</span>
              <br>
              <a href="https://sites.google.com/berkeley.edu/corl2020ropeuntangling/home">Website</a> / <a href="https://arxiv.org/pdf/2011.04999.pdf">PDF</a>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icra2020.gif" alt="rope-manip" width="280" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2003.01835">
                <papertitle>Learning Rope Manipulation Policies Using Dense Object Descriptors Trained on Synthetic Depth Data.</papertitle>
              </a>
              <br>
               <strong>Priya Sundaresan</strong>, Jennifer Grannen, Brijen Thananjeyan, Ashwin Balakrishna, Michael Laskey, Kevin Stone, Joseph E. Gonzalez, Ken Goldberg.
              <br>
              <span class="conference-badge badge-icra">ICRA 2020</span>
              <br>
              <a href="https://sites.google.com/view/ropemanipdescriptors/home">Website</a> / <a href="https://arxiv.org/pdf/2003.01835.pdf">PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/case2019.gif" alt="needle-extraction" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://goldberg.berkeley.edu/pubs/2019-CASE-sundaresan-needle-extraction-to-appear.pdf">
                <papertitle>Automated Extraction of Surgical Needles from Tissue Phantoms</papertitle>
              </a>
              <br>
               <strong>Priya Sundaresan</strong>, Brijen Thananjeyan, Johnathan Chiu, Danyal Fer, Ken Goldberg
              <br>
              <span class="conference-badge badge-icra">CASE 2019</span>
              <br>
              <a href="https://goldberg.berkeley.edu/pubs/2019-CASE-sundaresan-needle-extraction-to-appear.pdf">PDF</a>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>For Fun</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/doge_dodge.png" alt="diffcloud" width="280" height="30">
            </td>
            <td width="75%" valign="middle">
              <a href="game.html">
                <papertitle>Doge Dodge</papertitle>
              </a>
              <br>This is a silly little game I made which is heavily inspired by the Chrome T-Rex game that pops up when there's bad connectivity (s/o to UC Berkeley's wifi!), as well as my favorite game of all time, Crossy Road!! 
              <br>
              Credits: <a href="https://ebiten.org/">tile art and sound effects</a>, <a href="http://pixelartmaker.com/art/13d23ac43116c0c.png">doge art</a>, <a href="http://pixelartmaker.com/art/dc64eddc1719fb3.png">cactus art</a>, <a href="https://steamuserimages-a.akamaihd.net/ugc/96104387823325173/12EBB3BF7F176EFFCE809BFA500953E1F60F8825/">background art</a>, <a href="http://pixelartmaker.com/art/da268f06e621b21.png">rock art</a>, <a href="http://pixelartmaker.com/art/dca2574a41f6294.png">spike art</a>.
              <br>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- Progress bar -->
              <div style="width:100%;height:8px;background:#e0e0e0;border-radius:4px;margin-bottom:5px;position:relative;">
                <div id="progress" style="height:100%;width:0%;background:#3b8b5a;border-radius:4px;"></div>
                <span style="position:absolute;left:0;font-size:0.75rem;color:#555;">2013</span>
                <span style="position:absolute;right:0;font-size:0.75rem;color:#555;">2025</span>
              </div>
              <br><br>
          
              <div id="concert-map" style="width:100%;height:200px;border-radius:12px;overflow:hidden;"></div>
          
              <script src="https://unpkg.com/leaflet/dist/leaflet.js"></script>
              <link rel="stylesheet" href="https://unpkg.com/leaflet/dist/leaflet.css" />
          
              <script>
                const concerts = [
                  { artist: "Kelly Clarkson & Panic! At The Disco", venue: "Shoreline Amphitheatre", coords: [37.4241, -122.0806] },
                  { artist: "Flo Rida, 5SOS & Tori Kelly", venue: "California's Great America", coords: [37.4003, -121.9706] },
                  { artist: "G-Eazy", venue: "Fox Theater Oakland", coords: [37.8044, -122.2711] },
                  { artist: "Ed Sheeran", venue: "AT&T Park", coords: [37.7786, -122.3893] },
                  { artist: "Ravyn Lenae & Jorja Smith", venue: "Fox Theater Oakland", coords: [37.8044, -122.2711] },
                  { artist: "Grateful Dead", venue: "Shoreline Amphitheatre", coords: [37.4241, -122.0806] },
                  { artist: "LANY", venue: "Bill Graham Civic Auditorium", coords: [37.7830, -122.4039] },
                  { artist: "Thundercat & Anderson .Paak", venue: "Bill Graham Civic Auditorium", coords: [37.7830, -122.4039] },
                  { artist: "Dead & Company", venue: "Chase Center", coords: [37.7680, -122.3877] },
                  { artist: "Chelsea Cutler & Quinn", venue: "Greek Theatre Berkeley", coords: [37.8721, -122.2601] },
                  { artist: "Jeremy Zucker", venue: "Fox Theater Oakland", coords: [37.8044, -122.2711] },
                  { artist: "Valley", venue: "Rickshaw Stop", coords: [37.7760, -122.4193] },
                  { artist: "Omar Apollo", venue: "Masonic Auditorium", coords: [37.7830, -122.4335] },
                  { artist: "Conan Gray", venue: "Fox Theater Oakland", coords: [37.8044, -122.2711] },
                  { artist: "Raveena", venue: "Fox Theater Oakland", coords: [37.8044, -122.2711] },
                  { artist: "Sasha Sloan", venue: "The Fillmore SF", coords: [37.7840, -122.4334] },
                  { artist: "Lizzie McAlpine", venue: "Rickshaw Stop", coords: [37.7760, -122.4193] },
                  { artist: "LANY", venue: "Greek Theatre Berkeley", coords: [37.8721, -122.2601] },
                  { artist: "Omar Apollo", venue: "Masonic Auditorium", coords: [37.7830, -122.4335] },
                  { artist: "Steve Lacy, Foushee & Toro y Moi", venue: "Frost Amphitheatre", coords: [37.4292, -122.1700] },
                  { artist: "Del Water Gap & Maggie Rogers", venue: "Bill Graham Civic Auditorium", coords: [37.7830, -122.4039] },
                  { artist: "Boygenius", venue: "Frost Amphitheatre", coords: [37.4292, -122.1700] },
                  { artist: "The 1975", venue: "SAP Center San Jose", coords: [37.3320, -121.9010] },
                  { artist: "Dominic Fike", venue: "Frost Amphitheatre", coords: [37.4292, -122.1700] },
                  { artist: "Chelsea Cutler", venue: "Masonic Auditorium", coords: [37.7830, -122.4335] },
                  { artist: "Taylor Swift & Phoebe Bridgers", venue: "Lincoln Financial Field", coords: [39.9000, -75.1670] },
                  { artist: "Drake", venue: "Scotiabank Arena Toronto", coords: [43.6415, -79.3794] },
                  { artist: "LANY", venue: "Paramount Theatre Seattle", coords: [47.6097, -122.3331] },
                  { artist: "Noah Kahan", venue: "Greek Theatre Berkeley", coords: [37.8721, -122.2601] },
                  { artist: "Khruangbin", venue: "Greek Theatre Berkeley", coords: [37.8721, -122.2601] },
                  { artist: "Tems", venue: "Bill Graham Civic Auditorium", coords: [37.7830, -122.4039] },
                  { artist: "Dayglow", venue: "Fox Theater Oakland", coords: [37.8044, -122.2711] },
                  { artist: "Clairo", venue: "Frost Amphitheatre", coords: [37.4292, -122.1700] },
                  { artist: "Amin√© & Toro y Moi", venue: "Greek Theatre Berkeley", coords: [37.8721, -122.2601] },
                  { artist: "Hope Tala & Zayn", venue: "Bill Graham Civic Auditorium", coords: [37.7830, -122.4039] },
                  { artist: "Role Model", venue: "Fox Theater Oakland", coords: [37.8044, -122.2711] },
                  { artist: "Olivia Dean", venue: "Fox Theater Oakland", coords: [37.8044, -122.2711] }
                ];
          
                const map = L.map('concert-map', { zoomControl: false, attributionControl: false }).setView([37.7749, -122.4194], 4);
                
                L.tileLayer('https://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}{r}.png', {
                  subdomains: 'abcd',
                  maxZoom: 19
                }).addTo(map);
                
                const latlngs = concerts.map(c => c.coords);
                const polyline = L.polyline(latlngs, { color: '#3b8b5a', weight: 3 }).addTo(map);
                
                const marker = L.circleMarker(concerts[0].coords, { 
                  radius: 6, 
                  fillColor: '#3b8b5a', 
                  color: '#2c6b45', 
                  weight: 1, 
                  fillOpacity: 0.9 
                }).addTo(map);
                
                let popup = L.popup({ closeButton: false, autoClose: false, closeOnClick: false });
                let index = concerts.length - 1; // start at newest concert
                
                function showNextConcert() {
                  const c = concerts[index];
                
                  // Move marker
                  marker.setLatLng(c.coords);
                  map.setView(c.coords, 10, { animate: true });
                
                  // Fade-in popup
                  popup.setLatLng(c.coords)
                       .setContent(`<b>${c.artist}</b><br>${c.venue}`)
                       .openOn(map);
                
                  // Update progress bar
                  const progressPercent = ((index) / concerts.length) * 100;
                  document.getElementById('progress').style.width = progressPercent + '%';
                
                  // Move to previous concert, loop back to last at the start
                  index = (index - 1 + concerts.length) % concerts.length;
                }
                
                // start loop every 1.2s
                showNextConcert();
                setInterval(showNextConcert, 1200);
              </script>
            </td>
            <td width="75%" valign="middle">
              <br>
              <papertitle>Concerts I've Been To!</papertitle>
            </td>
          </tr>


        </tbody></table>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Shoutout to Jon Barron for the <a href="https://jonbarron.info/">awesome website template <3</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
