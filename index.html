<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Priya Sundaresan</title>
  
  <meta name="author" content="Priya Sundaresan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Priya Sundaresan</name>
              </p>
              <p>I am a 1st year PhD student at Stanford University, advised by Professor <a href="https://dorsa.fyi/">Dorsa Sadigh</a> in the <a href="https://iliad.stanford.edu/">Stanford Intelligent and Interactive Autonomous Systems Group (ILIAD)</a> and <a href="https://web.stanford.edu/~bohg/">Jeannette Bohg</a> in the <a href="">Interactive Perception and Robot Learning Lab</a>. I am interested in robot manipulation through multimodal perception, and I am funded by the <a href="https://www.nsfgrfp.org/">National Science Foundation Graduate Fellowship</a>.
              </p>
              <p>Before Stanford, I completed my B.S. and M.S. at UC Berkeley, where I worked with Professor <a href='goldberg.berkeley.edu'>Ken Goldberg</a> in the <a href='autolab.berkeley.edu'>AUTOLAB</a> under the <a href='https://bair.berkeley.edu/'>Berkeley AI Research (BAIR)</a> group.</p>
              <p style="text-align:center">
                <a href="mailto:priyasun@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="data/PriyaSundaresanCV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=7SUquR4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/priyasun_?lang=en">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/priyasundaresan/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/PriyaSundaresan.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/PriyaSundaresan.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/diffcloud.gif" alt="diffcloud" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2204.03139">
                <papertitle>DiffCloud: Real-to-Sim from Point Clouds with Differentiable Simulation and Rendering of Deformable Objects</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan</strong>, Rika Antonova, Jeannette Bohg
              <br>
              <em>International Conference on Intelligent Robots and Systems (IROS), 2022.</em>
              <br>
              <a href="https://sites.google.com/berkeley.edu/diffcloud/home">Website</a> / <a href="https://arxiv.org/abs/2204.03139">PDF</a> 
            </td>
          </tr>


         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ral2022.gif" alt="bayes-real2sim" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.05068">
                <papertitle>A Bayesian Treatment of Real-to-Sim for Deformable Object Manipulation</papertitle>
              </a>
              <br>
              Rika Antonova, Jingyun Yang, <strong>Priya Sundaresan</strong>, Dieter Fox, Fabio Ramos, Jeannette Bohg
              <br>
              <em>IEEE Robotics and Automation Letters (RA-L), 2022.</em>
              <br>
              <a href="https://arxiv.org/abs/2112.05068">PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iros2021.gif" alt="mult-cable-untangling" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2106.02252">
                <papertitle>Disentangling Dense Multi-Cable Knots</papertitle>
              </a>
              <br>
               Vainavi Viswanath*, Jennifer Grannen*, <strong>Priya Sundaresan*</strong>, Brijen Thananjeyan, Ashwin Balakrishna, Ellen Novoseller, Jeffrey Ichnowski, Michael Laskey, Joseph E. Gonzalez, Ken Goldberg
              <br>
              <em>International Conference on Intelligent Robots and Systems (IROS), 2021.</em>
              <br>
              <a href="https://sites.google.com/view/multi-cable-disentangling">Website</a> / <a href="https://arxiv.org/pdf/2106.02252.pdf">PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/rss2021.gif" alt="nonplanar-untangling" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://roboticsconference.org/program/papers/013/">
                <papertitle>Untangling Dense Non-Planar Knots by Learning Manipulation Features and Recovery Policies</papertitle>
              </a>
              <br>
               <strong>Priya Sundaresan*</strong>, Jennifer Grannen*, Brijen Thananjeyan, Ashwin Balakrishna, Jeffrey Ichnowski, Ellen Novoseller, Minho Hwang, Michael Laskey, Joseph E. Gonzalez, Ken Goldberg
              <br>
              <em>Robotics: Science and Systems (RSS), 2021.</em>
              <br>
              <a href="https://tinyurl.com/rssuntangling">Website</a> / <a href="http://www.roboticsproceedings.org/rss17/p013.pdf">PDF</a>
            </td>
          </tr>


         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icra2021.gif" alt="descriptors-fabric" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/pdf/2003.12698">
                <papertitle>Learning Dense Visual Correspondences in Simulation to Smooth and Fold Real Fabrics</papertitle>
              </a>
              <br>
              Aditya Ganapathi, <strong>Priya Sundaresan</strong>, Brijen Thananjeyan, Ashwin Balakrishna, Daniel Seita, Jennifer Grannen, Minho Hwang, Ryan Hoque, Joseph E. Gonzalez, Nawid Jamali, Katsu Yamane, Soshi Iba, Ken Goldberg
              <br>
              <em>International Conference on Robotics and Automation (ICRA), 2021.</em>
              <br>
              <a href="https://sites.google.com/view/fabric-descriptors">Website</a> / <a href="https://arxiv.org/pdf/2003.12698.pdf">PDF</a>
            </td>
          </tr>

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iros2020-wkshop.gif" alt="mmgsd" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2010.04339">
                <papertitle>MMGSD: Multi-Modal Gaussian Shape Descriptors for Correspondence Matching in 1D and 2D Deformable Objects.</papertitle>
              </a>
              <br>
              <strong>Priya Sundaresan*</strong>, Aditya Ganapathi*, Brijen Thananjeyan, Ashwin Balakrishna, Daniel Seita, Ryan Hoque, Joseph Gonzalez, Ken Goldberg
              <br>
              <em>International Conference on Intelligent Robots and Systems (IROS), Workshop on Robotic Manipulation of Deformable Objects, 2020.</em>
              <br>
              <a href="https://arxiv.org/abs/2010.04339">PDF</a>
            </td>
          </tr>


         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/corl2020_gif.gif" alt="untangling" width="280" height="l80">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2011.04999">
                <papertitle>Untangling Dense Knots by Learning Task-Relevant Keypoints</papertitle>
              </a>
              <br>
              Jennifer Grannen*, <strong>Priya Sundaresan*</strong>, Brijen Thananjeyan, Jeffrey Ichnowski, Ashwin Balakrishna, Minho Hwang, Vainavi Viswanath, Michael Laskey, Joseph E. Gonzalez, Ken Goldberg
              <br>
              <em>Conference on Robot Learning (CoRL), 2020.</em> <strong>Oral Presentation</strong>
              <br>
              <a href="https://sites.google.com/berkeley.edu/corl2020ropeuntangling/home">Website</a> / <a href="https://arxiv.org/pdf/2011.04999.pdf">PDF</a>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icra2020.gif" alt="rope-manip" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2003.01835">
                <papertitle>Learning Rope Manipulation Policies Using Dense Object Descriptors Trained on Synthetic Depth Data.</papertitle>
              </a>
              <br>
               <strong>Priya Sundaresan</strong>, Jennifer Grannen, Brijen Thananjeyan, Ashwin Balakrishna, Michael Laskey, Kevin Stone, Joseph E. Gonzalez, Ken Goldberg.
              <br>
             <em>International Conference on Robotics and Automation (ICRA), 2020.</em>
              <br>
              <a href="https://sites.google.com/view/ropemanipdescriptors/home">Website</a> / <a href="https://arxiv.org/pdf/2003.01835.pdf">PDF</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/case2019.gif" alt="needle-extraction" width="280" height="180">
            </td>
            <td width="75%" valign="middle">
              <a href="https://goldberg.berkeley.edu/pubs/2019-CASE-sundaresan-needle-extraction-to-appear.pdf">
                <papertitle>Automated Extraction of Surgical Needles from Tissue Phantoms</papertitle>
              </a>
              <br>
               <strong>Priya Sundaresan</strong>, Brijen Thananjeyan, Johnathan Chiu, Danyal Fer, Ken Goldberg
              <br>
              <em>Conference on Automation Science and Engineering (CASE), 2019.</em>
              <br>
              <a href="https://goldberg.berkeley.edu/pubs/2019-CASE-sundaresan-needle-extraction-to-appear.pdf">PDF</a>
            </td>
          </tr>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>For Fun</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/doge_dodge.png" alt="diffcloud" width="280" height="30">
            </td>
            <td width="75%" valign="middle">
              <a href="game.html">
                <papertitle>Doge Dodge</papertitle>
              </a>
              <br>This is a silly little game I made which is heavily inspired by the Chrome T-Rex game that pops up when there's bad connectivity (s/o to UC Berkeley's wifi!), as well as my favorite game of all time, Crossy Road!! 
              <br>
              Credits: <a href="https://ebiten.org/">tile art and sound effects</a>, <a href="http://pixelartmaker.com/art/13d23ac43116c0c.png">doge art</a>, <a href="http://pixelartmaker.com/art/dc64eddc1719fb3.png">cactus art</a>, <a href="https://steamuserimages-a.akamaihd.net/ugc/96104387823325173/12EBB3BF7F176EFFCE809BFA500953E1F60F8825/">background art</a>, <a href="http://pixelartmaker.com/art/da268f06e621b21.png">rock art</a>, <a href="http://pixelartmaker.com/art/dca2574a41f6294.png">spike art</a>.
              <br>
            </td>
          </tr>
        </tbody></table>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Shoutout to Jon Barron for the <a href="https://jonbarron.info/">awesome website template <3</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
